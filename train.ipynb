{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script aims to train our autoencoder on the clean training data that have been previously generated.\n",
    "\n",
    "Deepfake is implemented as an autoencoder. \n",
    "\n",
    "The face of the actor 1 is cropped and aligned to his face. Then the autoencoder learn how to encode and decode (reconstruct) the face. The goal here is to minimize the reconstruction error.\n",
    "\n",
    "\n",
    "<img src=\"image/encoder1.JPG\">\n",
    "\n",
    "The face of the actor 2 is cropped and aligned to his face. Then the autoencoder learn how to encode and decode (reconstruct) the face. The goal here is to minimize the reconstruction error. The interesting part is that the encoder is the same for actor 1 and 2.\n",
    "\n",
    "<img src=\"image/encoder2.JPG\">\n",
    "\n",
    "The goal is to find a mathematical function that for a face of the actor 1, outputs a face that looks like the actor 2.\n",
    "\n",
    "Note: these images don t belong to me and comes from the animation in the youtube video about deepfake made by Siraj Raval\n",
    "\n",
    "In contrast to the base version of Deepfakes, we provide a very conviniant way to speed up the training process via transfer learning. The idea is to load the weight of a pretrained network (for the same network configuration but for another face pair such as Donald ump and Nicolas Cage) These weights are used as a starting point to learn new weight. The netork will therefore converge faster thant if it would be trained from scratch. \n",
    "\n",
    "More advanced technique exists to apply transfer learning to autoencoder such [here](https://www.ijcai.org/Proceedings/15/Papers/578.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the various dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "from scandir import scandir\n",
    "\n",
    "from keras.models import Model as KerasModel\n",
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from lib_1.PixelShuffler import PixelShuffler\n",
    "import time\n",
    "import numpy\n",
    "from lib_1.training_data import minibatchAB, stack_images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the caracteristics of our network:\n",
    "   * sav_Model: the location of the model (it needs to be the absolute path)\n",
    "   * pretrained_weight: transfer learning can be used to speed up the learning process\n",
    "   * sav_Model: the location of the model (it needs to be the absolute path)\n",
    "   * image_actor_A_directory: the location of the training data for the actor A\n",
    "   * image_actor_B_directory: the location of the training data for the actor B\n",
    "   * batch_size: the batch size (1<< batch_size <<your training dataset size)\n",
    "       * a small batch_size enables poor hardware to run the training but the gradiant might be a bit noisy. I advice you to pick a batch size of 32 or 64\n",
    "   * save_interval: it define at which interval of time Keras should save your model\n",
    "   * IMAGE_SHAPE: the shape of the input image\n",
    "       * it must be consistant with the one you use during the prediction\n",
    "   * ENCODER_DIM: the dimension of the encoding in the autoencoder\n",
    "       * it must be consistant with the one you use during the prediction\n",
    "   \n",
    "I invite you to try different parameter until you get a satifying result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav_Model=\"/home/olivier/Desktop/face-swap/deepfakes/weight_repo\"\n",
    "pretrained_weight=\"/home/olivier/Desktop/face-swap/deepfakes/weight\"\n",
    "image_actor_A_directory=\"/home/olivier/Desktop/face-swap/daniel_craig/\"\n",
    "image_actor_B_directory=\"/home/olivier/Desktop/face-swap/pierce_broceman/\"\n",
    "batch_size=1\n",
    "save_interval=100\n",
    "ENCODER_DIM = 1024\n",
    "\n",
    "\n",
    "#DON'T MODIFY\n",
    "image_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
    "encoderH5 = '/encoder.h5'\n",
    "decoder_AH5 = '/decoder_A.h5'\n",
    "decoder_BH5 = '/decoder_B.h5'\n",
    "IMAGE_SHAPE = (64, 64, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model and its associated trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.model_dir = sav_Model\n",
    "        self.pretrained_weight=pretrained_weight\n",
    "        self.encoder = self.Encoder()\n",
    "        self.decoder_A = self.Decoder()\n",
    "        self.decoder_B = self.Decoder()\n",
    "\n",
    "        self.initModel()\n",
    "\n",
    "    \n",
    "    def initModel(self):\n",
    "        optimizer = Adam(lr=5e-5, beta_1=0.5, beta_2=0.999)\n",
    "        x = Input(shape=IMAGE_SHAPE)\n",
    "\n",
    "        self.autoencoder_A = KerasModel(x, self.decoder_A(self.encoder(x)))\n",
    "        self.autoencoder_B = KerasModel(x, self.decoder_B(self.encoder(x)))\n",
    "\n",
    "        self.autoencoder_A.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "        self.autoencoder_B.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "\n",
    "    def converter(self, swap):\n",
    "        autoencoder = self.autoencoder_B if not swap else self.autoencoder_A \n",
    "        return lambda img: autoencoder.predict(img)\n",
    "\n",
    "    def conv(self, filters):\n",
    "        def block(x):\n",
    "            x = Conv2D(filters, kernel_size=5, strides=2, padding='same')(x)\n",
    "            x = LeakyReLU(0.1)(x)\n",
    "            return x\n",
    "        return block\n",
    "\n",
    "    def upscale(self, filters):\n",
    "        def block(x):\n",
    "            x = Conv2D(filters * 4, kernel_size=3, padding='same')(x)\n",
    "            x = LeakyReLU(0.1)(x)\n",
    "            x = PixelShuffler()(x)\n",
    "            return x\n",
    "        return block\n",
    "\n",
    "    def Encoder(self):\n",
    "        input_ = Input(shape=IMAGE_SHAPE)\n",
    "        x = input_\n",
    "        x = self.conv(128)(x)\n",
    "        x = self.conv(256)(x)\n",
    "        x = self.conv(512)(x)\n",
    "        x = self.conv(1024)(x)\n",
    "        x = Dense(ENCODER_DIM)(Flatten()(x))\n",
    "        x = Dense(4 * 4 * 1024)(x)\n",
    "        x = Reshape((4, 4, 1024))(x)\n",
    "        x = self.upscale(512)(x)\n",
    "        return KerasModel(input_, x)\n",
    "\n",
    "    def Decoder(self):\n",
    "        input_ = Input(shape=(8, 8, 512))\n",
    "        x = input_\n",
    "        x = self.upscale(256)(x)\n",
    "        x = self.upscale(128)(x)\n",
    "        x = self.upscale(64)(x)\n",
    "        x = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(x)\n",
    "        return KerasModel(input_, x)\n",
    "        \n",
    "    def load(self, swapped):\n",
    "        (face_A,face_B) = (decoder_AH5, decoder_BH5) if not swapped else (decoder_BH5, decoder_AH5)\n",
    "\n",
    "        try:\n",
    "            self.encoder.load_weights(self.pretrained_weight + encoderH5)\n",
    "            self.decoder_A.load_weights(self.pretrained_weight + face_A)\n",
    "            self.decoder_B.load_weights(self.pretrained_weight + face_B)\n",
    "            print('loaded model weights')\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print('Failed loading existing training data.')\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "    def save_weights(self):\n",
    "        self.encoder.save_weights(self.model_dir + encoderH5)\n",
    "        self.decoder_A.save_weights(self.model_dir + decoder_AH5)\n",
    "        self.decoder_B.save_weights(self.model_dir + decoder_BH5)\n",
    "        print('saved model weights')\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, fn_A, fn_B, batch_size=64):\n",
    "        self.batch_size = batch_size\n",
    "        self.model = model\n",
    "        self.images_A = minibatchAB(fn_A, self.batch_size)\n",
    "        self.images_B = minibatchAB(fn_B, self.batch_size)\n",
    "\n",
    "    def train_one_step(self, iter):\n",
    "        epoch, warped_A, target_A = next(self.images_A)\n",
    "        epoch, warped_B, target_B = next(self.images_B)\n",
    "\n",
    "        loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)\n",
    "        loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)\n",
    "        print(\"[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}\".format(time.strftime(\"%H:%M:%S\"), iter, loss_A, loss_B),\n",
    "            end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(directory):\n",
    "    return [x.path for x in scandir(directory) if\n",
    "     any(map(lambda ext: x.name.lower().endswith(ext), image_extensions))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We launch the training. We will try to minimize th loss of the auto encoder A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data, this may take a while...')\n",
    "# this is so that you can enter case insensitive values for trainer\n",
    "\n",
    "model = Model()\n",
    "model.load(swapped=False)\n",
    "\n",
    "images_A = get_image_paths(image_actor_A_directory)\n",
    "images_B = get_image_paths(image_actor_B_directory)\n",
    "trainer = Trainer(model,images_A,images_B,batch_size=batch_size)\n",
    "\n",
    "for epoch in range(0, 1000000):\n",
    "\n",
    "    save_iteration = epoch % save_interval == 0\n",
    "\n",
    "    trainer.train_one_step(epoch)\n",
    "\n",
    "    if save_iteration:\n",
    "        model.save_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
